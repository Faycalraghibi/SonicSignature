{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Fingerprinting\n",
    "\n",
    "This notebook demonstrates the complete audio fingerprinting pipeline:\n",
    "1. Spectrogram computation (STFT)\n",
    "2. Local-maxima extraction\n",
    "3. Target-zone hashing\n",
    "4. Database construction and song identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Import the standalone fingerprinting module\n",
    "from Faycal_Raghibi_audio_fingerprinting import (\n",
    "    compute_spectrogram,\n",
    "    get_maxima,\n",
    "    process_signal,\n",
    "    AudioDatabase,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load an Audio File\n",
    "\n",
    "We load one of the provided classical music excerpts at the required sampling rate of 3000 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SONGS_DIR = \"../songs\"\n",
    "song_files = [f for f in os.listdir(SONGS_DIR) if f.endswith(\".mp3\")]\n",
    "print(f\"Available songs ({len(song_files)}):\")\n",
    "for s in song_files:\n",
    "    print(f\"  • {s}\")\n",
    "\n",
    "# Pick the first song for demonstration\n",
    "SONG_PATH = os.path.join(SONGS_DIR, song_files[0])\n",
    "y, sr = librosa.load(SONG_PATH, sr=3000)\n",
    "print(f\"\\nLoaded: {song_files[0]}\")\n",
    "print(f\"  Duration : {len(y)/sr:.1f} s\")\n",
    "print(f\"  Samples  : {len(y)}\")\n",
    "print(f\"  SR       : {sr} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spectrogram Computation\n",
    "\n",
    "The spectrogram is computed using the Short-Time Fourier Transform (STFT) with the following parameters:\n",
    "- `n_fft = 2048`\n",
    "- `hop_length = 512`\n",
    "- `win_length = 1024`\n",
    "\n",
    "We obtain the **energy spectrogram** $|V_g f(u, \\xi)|^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = compute_spectrogram(y, sr=sr)\n",
    "print(f\"Spectrogram shape: {S.shape}  (freq_bins x time_frames)\")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(\n",
    "    librosa.power_to_db(S, ref=np.max),\n",
    "    sr=sr, hop_length=512, x_axis=\"time\", y_axis=\"hz\"\n",
    ")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Energy Spectrogram\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Local Maxima (Constellation Map)\n",
    "\n",
    "We identify spectral peaks by finding local maxima in 3×3 grids, then filter by:\n",
    "- Amplitude threshold (90th percentile)\n",
    "- Minimum distance pruning (10 px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxima = get_maxima(S)\n",
    "print(f\"Detected {len(maxima)} spectral peaks\")\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(\n",
    "    librosa.power_to_db(S, ref=np.max),\n",
    "    sr=sr, hop_length=512, x_axis=\"time\", y_axis=\"hz\",\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.scatter(\n",
    "    maxima[:, 1] * 512 / sr,  # convert frames to seconds\n",
    "    maxima[:, 0] * sr / 2048, # convert bins to Hz\n",
    "    c=\"red\", s=5, marker=\".\", label=\"Peaks\"\n",
    ")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Constellation Map (spectral peaks overlaid)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hash Generation\n",
    "\n",
    "For each anchor peak, we define a **Target Zone** (300 px in time, 20 px in frequency) and pair the anchor with the top-10 peaks inside the zone.\n",
    "\n",
    "$$\\text{Hash} = f_{\\text{anchor}} \\times 10^6 + f_{\\text{target}} \\times 10^3 + (t_{\\text{target}} - t_{\\text{anchor}})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = process_signal(y, sr=sr)\n",
    "print(f\"Generated {len(hashes)} unique hashes\")\n",
    "print(\"\\nSample hashes (first 10):\")\n",
    "for i, (h, t) in enumerate(list(hashes.items())[:10]):\n",
    "    print(f\"  Hash: {h:>15d}   Anchor time frame: {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Database Construction\n",
    "\n",
    "We fingerprint every song in the `songs/` directory and store the resulting hash dictionaries in a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = \"../dataset/dataset.pickle\"\n",
    "db = AudioDatabase(db_path=DB_PATH)\n",
    "\n",
    "if not os.path.exists(DB_PATH):\n",
    "    print(\"Building database (this may take a few minutes)...\")\n",
    "    db.create_database(songs_dir=SONGS_DIR)\n",
    "else:\n",
    "    db.load_database()\n",
    "\n",
    "print(f\"\\nDatabase contains {len(db.database)} songs:\")\n",
    "for name in db.song_names:\n",
    "    print(f\"  • {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Song Identification\n",
    "\n",
    "We simulate a real-world query by taking a 10-second excerpt from one of the stored songs, fingerprinting it, and searching the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 10-second excerpt from the middle of the song\n",
    "excerpt_start = len(y) // 3\n",
    "excerpt_len = 10 * sr  # 10 seconds\n",
    "excerpt = y[excerpt_start : excerpt_start + excerpt_len]\n",
    "print(f\"Excerpt: {len(excerpt)/sr:.1f} s  (frames {excerpt_start}–{excerpt_start+excerpt_len})\")\n",
    "\n",
    "# Fingerprint the excerpt\n",
    "excerpt_hashes = process_signal(excerpt, sr=sr)\n",
    "print(f\"Excerpt hashes: {len(excerpt_hashes)}\")\n",
    "\n",
    "# Search\n",
    "from Faycal_Raghibi_audio_fingerprinting import search_song\n",
    "\n",
    "top_indices = search_song(db.database, excerpt_hashes)\n",
    "print(\"\\n--- Top 3 Matches ---\")\n",
    "for rank, idx in enumerate(top_indices, 1):\n",
    "    print(f\"  {rank}. {db.song_names[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "| Step | Description | Output |\n",
    "|------|-------------|--------|\n",
    "| 1 | Load audio at 3 kHz | Mono signal |\n",
    "| 2 | STFT (n_fft=2048, hop=512, win=1024) | Energy spectrogram |\n",
    "| 3 | 3×3 local-max + filtering | Constellation map |\n",
    "| 4 | Target-zone pairing + hashing | Dict of hashes |\n",
    "| 5 | Repeat for all songs → pickle DB | Persistent database |\n",
    "| 6 | Hash an excerpt, histogram match | Identified song |\n",
    "\n",
    "The system correctly identifies the source song from a short excerpt by matching the histogram of time-offset differences between shared hashes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
